{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../OCC' # change folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../OCC/OCC-2018-0038\n",
      "../OCC/OCC-2014-0008\n",
      "../OCC/OCC-2017-0018\n",
      "../OCC/OCC-2017-0011\n",
      "../OCC/OCC-2018-0009\n",
      "../OCC/OCC-2014-0001\n",
      "../OCC/OCC-2013-0013\n",
      "../OCC/OCC-2018-0030\n",
      "../OCC/CFPB-2012-0031\n",
      "../OCC/OCC-2014-0007\n",
      "../OCC/OCC-2018-0008\n",
      "../OCC/OCC-2014-0009\n",
      "../OCC/OCC-2017-0021\n",
      "../OCC/OCC-2018-0039\n",
      "../OCC/OCC-2019-0001\n",
      "../OCC/OCC-2016-0017\n",
      "../OCC/OCC-2012-0013\n",
      "../OCC/OCC-2019-0009\n",
      "../OCC/OCC-2016-0002\n",
      "../OCC/OCC-2012-0008\n",
      "../OCC/OCC-2019-0023\n",
      "../OCC/OCC-2020-0002\n",
      "../OCC/OCC-2018-0041\n",
      "../OCC/OCC-2013-0008\n",
      "../OCC/OCC-2014-0025\n",
      "../OCC/OCC-2018-0040\n",
      "../OCC/OCC-2013-0009\n",
      "../OCC/OCC-2014-0012\n",
      "../OCC/OCC-2018-0003\n",
      "../OCC/OCC-2013-0010\n",
      "../OCC/OCC-2017-0012\n",
      "../OCC/OCC-2014-0002\n",
      "../OCC/OCC-2017-0013\n",
      "../OCC/OCC-2013-0016\n",
      "../OCC/OCC-2011-0008\n",
      "../OCC/OCC-2016-0022\n",
      "../OCC/OCC-2019-0004\n",
      "../OCC/CFPB-2013-0020\n",
      "../OCC/OCC-2015-0021\n",
      "../OCC/OCC-2011-0023\n",
      "../OCC/OCC-2016-0009\n",
      "../OCC/OCC-2015-0017\n",
      "../OCC/OCC-2018-0020\n",
      "../OCC/OCC-2018-0011\n",
      "../OCC/OCC-2018-0029\n",
      "../OCC/OCC-2017-0008\n",
      "../OCC/OCC-2018-0010\n",
      "../OCC/OCC-2018-0026\n",
      "../OCC/OCC-2014-0016\n"
     ]
    }
   ],
   "source": [
    "res_dict = {}\n",
    "\n",
    "for entry in os.scandir(directory):\n",
    "    if (entry.path.endswith('.DS_Store')):\n",
    "        continue\n",
    "            \n",
    "    print(entry.path)\n",
    "    if not entry.path.endswith('.DS_Store'):\n",
    "        for subentry in os.scandir(entry.path):\n",
    "            if (subentry.path.endswith(\"Links.csv\") or \n",
    "                subentry.path.endswith(\"Links.txt\") or \n",
    "                subentry.path.endswith('.DS_Store')):\n",
    "                continue\n",
    "            \n",
    "            if subentry.path.endswith('Rule'):\n",
    "                docket_id = subentry.path.split('/')[2]\n",
    "                file_type = subentry.path.split('/')[3]\n",
    "\n",
    "#                 if docket_id not in res_dict:\n",
    "#                     res_dict[docket_id] = {}\n",
    "                if file_type not in res_dict:\n",
    "                    res_dict[file_type] = []\n",
    "\n",
    "               \n",
    "                for filename in os.listdir(subentry):\n",
    "                    if filename.endswith(\".txt\") and not filename.endswith(\"Links.txt\"):\n",
    "                        path_rule = os.path.join(subentry, filename)\n",
    "                        f = open(path_rule, \"r\", encoding=\"ISO-8859-1\")\n",
    "                        text = f.read()\n",
    "                        \n",
    "                        res_dict[file_type].append(text)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "            if subentry.path.endswith('Proposed Rule'):\n",
    "                    \n",
    "                for sub in os.scandir(subentry.path):\n",
    "                    if (sub.path.endswith(\"Links.csv\") or \n",
    "                        sub.path.endswith(\"Links.txt\") or \n",
    "                        sub.path.endswith('.DS_Store')):\n",
    "                        continue\n",
    "                    docket_id = sub.path.split('/')[2]\n",
    "                    file_type = sub.path.split('/')[3]\n",
    "                    pro_rule_id = sub.path.split('/')[4]\n",
    "\n",
    "#                     if docket_id not in res_dict:\n",
    "#                         res_dict[docket_id] = {}\n",
    "                    if file_type not in res_dict:\n",
    "                        res_dict[file_type] = []\n",
    "                  \n",
    "                   \n",
    "\n",
    "                    for pro_rule_entry in os.scandir(sub.path):\n",
    "#                         if pro_rule_entry.path == './CFPB/CFPB-2011-0023/Proposed Rule/CFPB-2011-0023-0001_content.pdf':\n",
    "#                             continue\n",
    "                        if (pro_rule_entry.path.endswith(\"Links.csv\") or \n",
    "                        pro_rule_entry.path.endswith(\"Links.txt\") or \n",
    "                        pro_rule_entry.path.endswith('.DS_Store')):\n",
    "                            continue\n",
    "                        \n",
    "                        if pro_rule_entry.path.endswith('txt'):\n",
    "                        \n",
    "                            path = pro_rule_entry.path\n",
    "                            f = open(path, \"r\", encoding=\"ISO-8859-1\")\n",
    "                            text = f.read()\n",
    "                            \n",
    "                            res_dict[file_type].append(text)\n",
    "                            \n",
    "                        \n",
    "                        if pro_rule_entry.path.endswith('comment'):\n",
    "                            if 'comment' not in res_dict:\n",
    "                                res_dict['comment'] = []\n",
    "                             \n",
    "                            for filename_path in os.scandir(pro_rule_entry.path):\n",
    "                                filename = filename_path.path\n",
    "                                if filename.endswith(\".txt\") and not filename.endswith(\"Links.txt\"):\n",
    "                                    f = open(filename, \"r\", encoding=\"ISO-8859-1\")\n",
    "                                    text = f.read()\n",
    "                                    \n",
    "                                    res_dict['comment'].append(text)\n",
    "                    else:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dict['OCC-2018-0038']['comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [('Rule', ''.join(res_dict['Rule'])), \n",
    "         ('Proposed Rule', ''.join(res_dict['Proposed Rule'])), \n",
    "         ('Comment', ''.join(res_dict['comment']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LENGTH = 6\n",
    "DELETE_WORDS = ['final rule', 'US', 'subject', 'OCC', \n",
    "                'purpose', 'provide', 'believe', 'include', 'required', \n",
    "                'require', 'may', 'proposed rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unwanted words\n",
    "#As we look at the cloud, we can get rid of words that don't make sense by adding them to this variable\n",
    "\n",
    "def remove_words(text_string,DELETE_WORDS=DELETE_WORDS):\n",
    "    for word in DELETE_WORDS:\n",
    "        text_string = text_string.replace(word,' ')\n",
    "    return text_string\n",
    "\n",
    "#Remove short words\n",
    "def remove_short_words(text_string,min_length = MIN_LENGTH):\n",
    "    word_list = text_string.split()\n",
    "    for word in word_list:\n",
    "        if len(word) < min_length:\n",
    "            text_string = text_string.replace(' '+word+' ',' ',1)\n",
    "    return text_string\n",
    "\n",
    "\n",
    "#Set up side by side clouds\n",
    "COL_NUM = 3\n",
    "ROW_NUM = 1\n",
    "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize=(18,12))\n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    text_string = remove_words(texts[i][1])\n",
    "    text_string = remove_short_words(text_string)\n",
    "    ax = axes[i] \n",
    "    ax.set_title(texts[i][0])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',width=1200,height=1000,max_words=20).generate(text_string)\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
